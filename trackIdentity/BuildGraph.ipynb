{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "import itertools\n",
    "from ast import literal_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = pickle.load(open('/home/osboxes/proj/twitter/trackIdentity/graphdf.pkl', 'rb'))\n",
    "filename = '/home/osboxes/proj/twitter/tweets.data'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def RetrieveTweetsFromLastPoint(filename,LineMemorisied):\n",
    "\n",
    "    # Initialisation\n",
    "    maliste = []\n",
    "    errors = 0\n",
    "    ntweets = 0\n",
    "    \n",
    "    # Read New Tweets\n",
    "    with open(filename) as fp:\n",
    "        for line in fp:\n",
    "            ntweets = ntweets + 1 \n",
    "            if ntweets > LineMemorisied:\n",
    "                try:\n",
    "                    maliste.append(literal_eval(line))\n",
    "                except:\n",
    "                    errors = errors + 1\n",
    "\n",
    "    return maliste,errors,ntweets,LineMemorisied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "maliste,NewErrors,NewNtweets,NewLineMemorisied = RetrieveTweetsFromLastPoint(filename,0)\n",
    "tdf = pd.DataFrame(maliste)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = tdf[[\"USERNAME\",\n",
    "         \"USERID\",\n",
    "         \"USERFOLLOWERS\",\n",
    "         \"USERFNAME\",\n",
    "         \"USERDESCRIPTION\"]].\\\n",
    "rename(columns = {\"USERNAME\" : \"NAME\",\n",
    "                  \"USERID\" : \"ID\",\n",
    "                  \"USERFOLLOWERS\" : \"NFOL\",\n",
    "                  \"USERFNAME\" : \"FNAME\",\n",
    "                  \"USERDESCRIPTION\":\"DESCRIPTION\"})\n",
    "\n",
    "b = tdf[[\"AUTHORNAME\",\n",
    "         \"AUTHORID\",\n",
    "         \"AUTHORFOLLOWERS\",\n",
    "         \"AUTHORFNAME\",\n",
    "         \"AUTHORDESCRIPTION\"]].\\\n",
    "rename(columns = {\"AUTHORNAME\" : \"NAME\",\n",
    "                  \"AUTHORID\" : \"ID\",\n",
    "                  \"AUTHORFOLLOWERS\" :\"NFOL\",\n",
    "                  \"AUTHORFNAME\":\"FNAME\",\n",
    "                  \"AUTHORDESCRIPTION\":\"DESCRIPTION\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "tdf = pd.concat([a,b],axis=0, sort=False)\n",
    "tdf.sort_values(by=\"FNAME\",ascending=False,inplace=True)\n",
    "tdf = tdf.drop_duplicates(subset = [\"ID\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "final = gdf.\\\n",
    "merge(tdf,how=\"left\",left_on=\"A\",right_on=\"ID\",).\\\n",
    "rename(columns = {\"NAME\" : \"ANAME\",\n",
    "                  \"NFOL\":\"ANFOL\",\n",
    "                  \"DESCRIPTION\" : \"ADESCRIPTION\",\"FNAME\":\"AFNAME\"}).drop(columns='ID')\n",
    "\n",
    "final = final.\\\n",
    "merge(tdf,how=\"left\",left_on=\"B\",right_on=\"ID\").\\\n",
    "rename(columns = {\"NAME\" : \"BNAME\",\n",
    "                  \"NFOL\":\"BNFOL\",\n",
    "                  \"DESCRIPTION\" : \"BDESCRIPTION\",\"FNAME\":\"BFNAME\"}).drop(columns=['ID'])\n",
    "\n",
    "final.sort_values(by=\"f\",ascending=False,inplace=True)\n",
    "final = final[final.A != final.B]\n",
    "final.reset_index(drop=True,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(final, open('/home/osboxes/proj/twitter/trackIdentity/GraphIdentity.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nombre de links : 3561\n"
     ]
    }
   ],
   "source": [
    "print(\"Nombre de links :\",len(final))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                     A                    B   f\n",
      "0             33962372  1121856729787043842  18\n",
      "1  1121856729787043842             33962372  18\n",
      "2           3373762791            572122341  15\n",
      "3   727425382169849856   827151086733635584  15\n",
      "4   727425382169849856   901893722857766912  15\n"
     ]
    }
   ],
   "source": [
    "print(\"\")\n",
    "print(final[[\"A\",\"B\",\"f\"]].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "final.to_csv(\"graph.csv\",index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "twitter",
   "language": "python",
   "name": "twitter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
